---
layout : post
categories : statistics, R
title : 추론, 분석
tags : [statistics, R]
date-string : December 09, 2023
---

# 추론, 분석

## 두 모집단의 분산에 대한 추론
 - $$모분산 : \sigma^2_1, \sigma^2_2인\ 두\ 정규모집단$$
   $$n_1, n_2개를\ 단순확률추출\ 그\ 표본의\ 분산이\ S^2_1, S^2_2$$
   $$\frac{S^2_1/\sigma^2_1}{S^2_2/\sigma^2_2}의\ 표집분포는$$ $$분자자유도:n_1-1,\ 분모자유도:n_2-1인\ F분포 따름$$

  $$\frac{S^2_1/ \sigma ^2_1}{S^2_2 / \sigma ^2_2} \sim F\_(n_1 - 1, n_2 - 1)$$

## F분포
 - F분포는 두 정규모집단의 분산을 비교
   - 카이제곱은 한 정규모집단의 모분산을 추론
![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/F-distribution_pdf.svg/405px-F-distribution_pdf.svg.png)

### 예제
 - 두 집단에 대해 각각 31개와 21개의 독립표본을 얻어 각각에 대한 표본분산이 9.4와 7.0임을 얻었다. 첫번째 집단의 분산이 두번째보다 큰가?

```R
pf(9.4/7.0, 31, 21, lower.tail = F)
```

## 분산분석(ANOVA)
 - 서로 독립인 모집단이 3개 이상인 경우 평균을 비교하거나 범주형 설명변수가 2개 이상인 인과 관계 분석
 - 종류
   - 종속변수와 독립변수의 수에 따라 분산분석 종류가 바뀜
     - 단일변량분산분석 - 일원분산분석 vs 이원분산분석
     - 다변량분산분석

## 사후분석
 - Tukey
 - Bonferroni
 - Scheffe
 - Duncan

### 일원분산분석
 - 독립변수 1개 + 종속변수 1개
 - 집단간 종속변수의 평균차이를 분석
 - 전제조건
   - 독립성 - 각 집단은 서로 독립적
   - 정규성 - 각 짖ㅂ단은 정규분포
   - 불편성 - 각 집단은 비슷한 분산
 - 귀무가설 : 평균이 모두 같다
 - 총편차 = 관측치 - 전체평균 = 집단 간 편차 + 집단 내 편차
 - 총변량(SST), 집단간변량(SSB), 집단내변량(SSW)
 - $$F = \frac{집단간제곱평균}{집단내제곱평균} = \frac{SSB/(c-1)}{SSW(N-c)}$$

#### 예제1

|A|B|C|
|--|--|--|
|6|8|13|
|8|12|9|
|4|9|11|
|5|11|8|
|3|6|7|
|4|8|12|

 - 집단간 제곱평균 = SSB/c-1
  = $$\frac{6 \times (5 - 8)^2 + 6 \times (9-8)^2 + 6 \times (10-8)^2}{3-1}= \frac{84}{2} = 42$$
 - 집단내제곱평균 = SSW(N-c)
  = $$\frac{(6-5)^2 + \cdots + (8-9)^2 + \cdots + (13-10)^2 + \cdots}{18 - 3} = \frac{68}{15} \approx 4.53$$
 - $$F = \frac{(집단간제곱평균)}{(집단내제곱평균)} \approx \frac{42}{4.53} \approx 9.26$$

```R
groupz <- c(rep("A",6),rep("B",6),rep("C",6))
dataz <- c(6,8,4,5,3,4, 8,12,9,11,6,8, 
           13,9,11,8,7,12)
data_fr <- data.frame(groupz,dataz)
#basic info
meanz <- c(mean(data_fr[groupz=="A",]$dataz),
             mean(data_fr[groupz=="B",]$dataz),
             mean(data_fr[groupz=="C",]$dataz))
meanz
mean(dataz)
#ssb~집단간변량
ssbz <- var(meanz)*6
#ssw~집단내변량
sswz <- (var(data_fr[groupz=="A",]$dataz)*5 +
             var(data_fr[groupz=="B",]$dataz)*5 +
             var(data_fr[groupz=="C",]$dataz)*5)/15
#compare~
pf(ssbz/sswz, 3-1, 18-3, lower.tail = F)
qf(0.05, 3-1, 18-3, lower.tail = F)
summary(aov(dataz ~ groupz, data = data_fr))
TukeyHSD(aov(dataz~groupz, data = data_fr))
```

### 이원분산분석
 - 독립변수 2개 + 종속변수 1개
 - 주효과 - 한 독립변수의 변화가 결과변수에 미치는 영향
 - 상호작용효과 - 다른 독립변수의 변화에 따라 한 독립변수가 결과변수에 미치는 영향
 - 귀무가설
   - 두 독립변수의 상호작용효과는 없다
     - 독립변수1에 따른 집단간 차이가 없다
     - 독립변수2에 따른 집단간 차이가 없다
 - 총변량 = 독립변수 1에 의한 변량 + 독립변수2에 의한 변량 + 설명되지 않는 변량
 - 각 독립변수에 따른 제곱의 평균
 - 상호작용에 따른 제곱의 평균
 - 경우에 따른 제곱의 평균
 - F는 3가지 경우에 따른 제곱의 평균 대비 3가지 값 고려

#### 예제

```R
#가상의 데이터 생성
set.seed(123)
#factor A의 수준
factor_A <- factor(rep(c("A1", "A2", "A3"), each = 10))
#factor B의 수준
factor_B <- factor(rep(c("B1", "B2"), each = 15))
# 가상의 응답 변수
response <- rnorm(30, mean = 50, sd = 10)
# 데이터 프레임 생성
data <- data.frame(FactorA = factor_A, FactorB = factor_B, Response = response)
# 이원분산분석 수행
model <- aov(Response ~ FactorA * FactorB, data = data)
# 분산분석 결과 확인
summary(model)
```