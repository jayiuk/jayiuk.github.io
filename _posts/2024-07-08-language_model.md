---
published : true
layout : post
categories : NLP, AI
title : 언어 모델
tags : [NLP, AI]
date-string : July 08, 2024
---

# 언어모델
## 언어모델 이란
- 언어라는 현상을 모델링 하고자 단어 시퀀스(문장)에 확률을 할당하는 모델

## 언어모델 구현 방법
- 통계를 이용한 방법
- 인공 신경망을 이용한 방법
### 최근엔 인공 신경망을 활용한 방법이 성능이 더 좋음
- GPT, BERT -> 인공신경망 언어모델

## 언어모델
- 단어 시퀀스에 확률을 할당
  - 가장 자연스러운 단어 시퀀스를 찾아내는 모델
  - 이전 단어들이 주어졌을 때 다음 단어를 예측

## 언어 모델링
- 주어진 단어들로부터 아직 모르는 단어를 예측하는 작업
  - 예전 단어들로부터 다음 단어를 예측하는 일

## 단어 시퀀스의 확률 할당
### 필요성
- 기계 번역
  - P(나는 버스를 탔다) > P(나는 버스를 탄다)
  - 언어 모델은 두 단어 시퀀스를 비교해 좌측의 확률이 더 높다고 판다
- 오타 교정
  - 선생님이 교실로 부리타케
  - P(달려갔다) > P(잘려갔다)
  - 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단

- 음성 인식
  - P(나는 메롱을 먹는다) < P(나는 메론을 먹는다)
  - 언어모델은 두 문장을 비교하여 우측의 문장의 확률이 더 높다고 판단

## 주어진 이전 단어들로부터 다음 단어 예측
- 언어모델 : 단어시퀀스에 확률을 할당
  - 이를 위해 가장 보편적으로 활용하는 방법 : 이전 단어들이 주어졌을 때 다음 단어를 예측하도록 하는 것

### 조건부확률로 표현
- w : 하나의 단어, W : 단어 시퀀스
- 단어 시퀀스 확률
  - $$P(W) = P(w_1, w_2, w_3, \dots, w_n)$$

- 다음 단어 등장 확률
  - $$P(w_n | w_1, \dots, w_{n-1})$$

  - W의 확률은 모든 단어가 예측된 후에 알 수 있음
     - $$P(W) = P(w_1, w_2, \dots, w_n) = \prod_{i = 1}^n P(wi|w_1, \dots, w_{i-1})$$
