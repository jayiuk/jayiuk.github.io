---
published : true
layout : post
categories : NLP, AI
title : TF-IDF(Term Frequency-Inverse Document Frequency)
tags : [NLP, AI]
date-string : July 10, 2024
---

# TF-IDF

## TF-IDF란
- 단어의 빈도와 역 문서 빈도를 사용
- DTM내의 각 단어들에 중요한 정도를 가중치로 줌
- 문서의 유사도, 검색 결과 중요도를 구하는 작업에서 쓰임

### TF-IDF 의미
- TF X IDF
- 문서를 d, 단어를 t, 문서의 총 개수를 n

#### 1. tf(d, t) : 특정 문서 d에서 특정 단어 t의 등장 횟수
- DTM에서 각 단어들이 가진 값
#### 2. df(t) : 특정 단어 t가 등장한 문서의 수
- 특정 단어 t가 등장한 문서의 수(그 외에는 고려사항 아님)
#### 3. idf(t) : df(t)에 반비례하는 수
$$idf(t) \;=\; log(\frac{n}{1 + df(t)})$$
- log를 사용하지 않으면 idf의 값이 지나치게 커짐
- 분모에 1을 더함 : 분모가 0이 되는 것을 방지
### TF-IDF 특장
- 모든 문서에서 자주 등장하는 단어는 안중요하다고 판단
  - 모든 문서에서 자주 등장하면 tf가 높아지지만 idf는 더 작아짐
  - 결국엔 TF-IDF의 값이 작아짐
- 불용어는 자연스럽게 중요도가 낮아진다
  - 거의 대부분의 문서에서 자주 등장하기 때문

## TF-IDF 예시
- DTM 예시 활용
- 문서1 : 먹고 싶은 사과
- 문서2 : 먹고 싶은 바나나
- 문서3 : 길고 노란 바나나 바나나
- 문서4 : 저는 과일이 좋아요

|구분|과일이|길고|노란|먹고|바나나|사과|싶은|저는|좋아요|
|---|---|---|---|---|---|---|---|---|---|
|문서1|0|0|0|1|0|1|1|0|0|
|문서2|0|0|0|1|1|0|1|0|0|
|문서3|0|1|1|0|2|0|0|0|0|
|문서4|1|0|0|0|0|0|0|1|1|

- IDF 계산

|단어|IDF|
|-----|--------|
|과일이|ln(4/(1+1)) = 0.693147|
|길고|ln(4/(1+1)) = 0.693147|
|노란|ln(4/(1+1)) = 0.693147|
|먹고|ln(4/(1+2)) = 0.287682|
|바나나|ln(4/(1+2)) = 0.287682|
|사과|ln(4/(1+1)) = 0.693147|
|싶은|ln(4/(1+2)) = 0.287682|
|저는|ln(4/(1+1)) = 0.693147|
|좋아요|ln(4/(1+1)) = 0.693147|

- TF-IDF 적용

|구분|과일이|길고|노란|먹고|바나나|사과|싶은|저는|좋아요|
|---|---|---|---|---|---|---|---|---|---|
|문서1|0|0|0|0.287682|0|0.693147|0.287682|0|0|
|문서2|0|0|0|0.287682|0.287682|0|0.287682|0|0|
|문서3|0|0.693147|0.693147|0|0.575364|0|0|0|0|
|문서4|0.693147|0|0|0|0|0|0|0.693147|0.693147|

