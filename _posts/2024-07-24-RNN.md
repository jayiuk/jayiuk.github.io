---
published : true
layout : post
categories : NLP, AI
title : 순환 신경망
tags : [NLP, AI]
date-string : July 24, 2024
---

# Recurrent Neural Network
## 순환신경망
- 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층으로도 보내면서 은닉층의 다음 계산의 입력으로 보냄
![rnn_image1_ver2](https://github.com/user-attachments/assets/411525b8-99e0-4758-a0c3-8c68859e0692)

- 메모리 셀(셀, RNN셀) : 은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드
  - 재귀적 활동
    - 각각의 시점에서 바로 이전 시점에서의 은닉층의 메모리 셀에서 나온 값을 자신의 입력으로 사용
  - 은닉 상태 : t+1의 자신에게 보내는 값
    - t시점의 메모리 셀은 t-1 시점의 메모리 셀이 보낸 은닉 상태를 t시점의 은닉 상태 계산을 위한 입력값으로 사용

![rnn_image2_ver3](https://github.com/user-attachments/assets/322f9ae3-f733-467d-818c-51cea604ace8)
- 위의 그림과 같은 그림. 풀어서 그린 버전

## RNN 특징
- 뉴런이라는 표현을 잘 사용안함
- 입력 벡터, 출력 벡터, 은닉 상태라는 표현을 주로 사용

![rnn_image2 5](https://github.com/user-attachments/assets/3d3a4a1f-d907-478d-8033-5a1f6baa4b63)
- RNN을 뉴런 단위로 표현한 그림
  - 입력 벡터의 차원 : 4
  - 은닉 상태의 크기 : 2
  - 출력 벡터의 차원 : 2

## RNN 형태
- 입력과 출력의 길이를 다르게 설계 가능
- 메모리 셀의 각 시점의 입, 출력의 단위 : 보편적인 단위는 단어 벡터
- 예시
  - 일 대 다(one-to-many) 구조
    - 하나의 입력에 대한 시퀀스 출력
  - 다 대 일(many-to-one) 구조
    - 단어 시퀀스로 부터 하나의 출력
  - 다 대 다(many-to-many) 구조
    - 문장 입력, 문장 출력

## RNN 수식
![rnn_image4_ver2](https://github.com/user-attachments/assets/5345ee9a-26a6-4522-a81c-8a9c4a7cb8c4)

- t시점에서의 은닉상태 값
$$h_t$$
- 입력층을 위한 가중치
  - $$W_x$$
- t-1의 은닉 상태값을 위한 가중치
  - $$W_h$$

$$은닉층:h_t = tanh(W_xx_t+W_hh_{t-1} + b)$$
$$출력층:y_t = f(W_yh_t+b)$$
- f는 비선형 활성화 함수 중 하나