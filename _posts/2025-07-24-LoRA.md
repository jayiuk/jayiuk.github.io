---
published : true
layout : post
categories : LLM, AI, LoRA
title : LoRA 논문 리뷰
tags : [LLM, AI, LoRA]
date-string : July 24, 2025
---

# LoRA
## 요약
- 학습된 모델의 가중치를 고정
- 훈련 가능한 분해 가중치를 트랜스포머 아키텍처의 각 레이어에 주입
    - 튜닝에 필요한 파라미터 수를 줄임


## LLM 튜닝
- LLM이 있다고 가정
    - 필요하면 파인튜닝
    - 이 때 모든 가중치를 업데이트
    - 이 경우 시간과 비용이 많이 소모됨

## LoRA 이전 방식

- 특정한 태스크의 파라미터들을 Pretrained Model에 주입
    - 추론 지연 발생
        - 모델 깊이를 연장시키거나, 모델의 사용 가능한 시퀀스 길이를 줄이기 때문.
    - 효율성과 모델 성능의 트레이드 오프 조정도 실패

## LoRA의 이론적 기반
- 과도하게 파라미터가 많은 모델이 실제로 낮은 고유 차원에 있다
    - 파라미터가 아무리 많아도 실제로 사용하는 파라미터 수는 적다
    - => 성능 향상에 영향을 주는 파라미터는 전체 파라미터의 일부
    - => 모델 adaptation하는 동안 가중치 변화도 일부만 될 것이다

## LoRA의 장점
- LoRA 모듈을 통해 다른 작업에 더 효과적으로 대응 가능
- 학습 효율
    - 랭크 분해 행렬만 최적화 시키기 때문
- 풀 파인튜닝에 비해 더 적은 추론 지연

## LoRA의 간략한 설명
- 트랜스포머 레이어 dmodel의 인풋과 아웃풋 사이즈를 불러옴
- self-attention 모듈에 있는 query/key/value/output 투영행렬 $$W_q, W_k, W_v, W_o$$사용
- $$W, W_{\theta}$$는 학습된 가중치 행렬
- $$\Delta W$$는 adaption동안 업데이트
    - $$\Delta W$$는 adaptation 동안의 변화량
        - gradient(손실함수의 기울기)들이 누적되면 변화량을 뜻함
- r = LoRA 모듈의 랭크
- 트랜스포머 구조를 그대로 참조


## 기존 파인튜닝
- 하나의 LLM이 있다고 가정
    - 각기 다른 특정 작업에선 성능이 좋진 않다
    - 이 문제를 해소하기 위해선 파인튜닝 필요
        - 이 경우 $$Z = {(x_i, y_i)}_{i = 1, 2, ..., N}$$ 형식의 데이터셋 필요
    - 재학습 시 기존의 파라미터 만큼의 새로운 파라미터 학습
        -> 모델 저장 및 배포에 어려움이 생긴다

## LoRA가 가지는 차이점
$$\triangle\Phi = \triangle\Phi(\theta)$$
- 위의 식은 LoRA가 파라미터 변화량을 만드는 방식
- LoRA는 변화량을 더 작은 집합인 $$\theta$$를 통해 구한다.
- $$\triangle\Phi \, 를\, 찾는 \, 것이\, \theta$$를 최적화하는 것이 된다.
- 즉 변화량을 더 작은 크기의 파라미터 $$\theta \, 로 \, 구하므로\, \theta$$만 학습시키면 된다
- => 더 효율적인 학습이 가능해짐

## 이 논문에서 사용한 방법
### 가정 : LLM은 특정 태스크에 사용될 때 일부 파라미터만 사용
- 언어모델의 가중치 행렬
    - $$W_0 \in R^{d \times K}$$
- 이를 더 작은 랭크로 분해
    - $$W_0 + \triangle W = W_0 + BA,\, where\, B \in R^{d \times r},\, A \in R^{r \times k},\, r << min(d, k) $$
- 학습동안 $$W_0$$는 고정, A, B에 훈련 가능한 파라미터 포함
- $$W_0,\, \triangle W = BA$$는 각각 같은 인풋으로 곱해진다
- 아웃풋 벡터는 같는 좌표로 합해짐
    - $$h = W_0 x + \triangle W_0 x = W_0 x + BA$$
- A는 가우시안 분포를 따르는 랜덤 난수로 초기화, B는 0으로 초기화
- $$\triangle W$$는 훈련 초기에 0으로 초기화
- $$\triangle W \, 를\, \frac{\alpha}{r}$$로 스케일링
    - $$\alpha$$는 r값에 따라 정해진 상수
- Adam으로 옵티마이징할 때 초기화를 적절하게 스케일링 했다면 알파를 조정하는 것은 학습률을 조정하는 것과 같게 된다